{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "###### NICK: YOU NEED TO PUT YOUR PERSONAL EXECUTABLE PATH HERE\n",
    "\n",
    "executable_path = \"C:/Users/nicho/Documents/Code/chromedriver.exe\"\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import os\n",
    "from lxml import html\n",
    "from lxml import etree\n",
    "from io import StringIO, BytesIO\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import timedelta, datetime\n",
    "from pandas.tseries.holiday import USFederalHolidayCalendar\n",
    "\n",
    "class LastDate:\n",
    "    \n",
    "    def __init__(self):\n",
    "        now = datetime.today()\n",
    "        self.current_year = now.year\n",
    "        self.current_day = now.replace(hour=0, minute=0, second=0, microsecond=0)\n",
    "        self.cal = USFederalHolidayCalendar()\n",
    "\n",
    "    def _most_recent_workday(self, last_day):\n",
    "        #returns most recent workday, accounting for federal holidays and weekends\n",
    "        self.holidays = self.cal.holidays(datetime(self.input_year, 1, 1), datetime(self.input_year, 12, 31)).to_pydatetime()\n",
    "        if self.search_date.weekday() < 5 and self.search_date not in self.holidays:\n",
    "            pass\n",
    "        elif self.search_date.weekday() < 5 and self.search_date in self.holidays:\n",
    "            self.search_date = (self.search_date - timedelta(days = 1))\n",
    "            if self.search_date.weekday() < 5:\n",
    "                pass\n",
    "            else:\n",
    "                difference = (self.search_date.weekday() - 4)\n",
    "                self.search_date = (self.search_date - timedelta(days=difference))\n",
    "        else:\n",
    "            difference = (self.search_date.weekday() - 4)\n",
    "            self.search_date = (self.search_date - timedelta(days=difference))\n",
    "        return self.search_date\n",
    "\n",
    "    # function returns most recent weekday with an option to manually override\n",
    "    def date_to_search(self, year, subtract_days = 1):\n",
    "        if len(str(year)) != 4:\n",
    "            return Exception('year format must conform to XXXX')\n",
    "        else:\n",
    "            pass\n",
    "        self.input_year = year\n",
    "        if self.input_year == self.current_year:\n",
    "            self.search_date = (self.current_day - timedelta(days=subtract_days))\n",
    "            return self._most_recent_workday(self.search_date)\n",
    "        else:\n",
    "            self.search_date = (datetime(self.input_year, 12, 31) - timedelta(days=(subtract_days - 1)))\n",
    "            return self._most_recent_workday(self.search_date)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "import shutil\n",
    "from fake_useragent import UserAgent\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.chrome.options import Options\n",
    "\n",
    "\n",
    "class SeleniumSite:\n",
    "\n",
    "    download_dir = '/test/'\n",
    "    \n",
    "    def _init_chrome_driver(self, headless=True, random_user=False):\n",
    "        chrome_options = self._build_chrome_options(headless=headless)\n",
    "        #executable_path = shutil.which('chromedriver')\n",
    "        options=chrome_options,\n",
    "        driver = webdriver.Chrome( executable_path=executable_path)\n",
    "        return driver\n",
    "\n",
    "    def _build_chrome_options(self, headless=True, random_user=False):\n",
    "        chrome_options = Options()\n",
    "        if headless:\n",
    "            chrome_options.add_argument(\"--headless\")\n",
    "        if random_user:\n",
    "            chrome_options.add_argument(\"--window-size=1920x1080\")\n",
    "            chrome_options.add_argument(\"--disable-notifications\")\n",
    "            chrome_options.add_argument('--no-sandbox')\n",
    "            chrome_options.add_argument('--verbose')\n",
    "            chrome_options.add_experimental_option(\"prefs\", {\n",
    "                    \"download.default_directory\": self.download_dir,\n",
    "                    \"download.prompt_for_download\": False,\n",
    "                    \"download.directory_upgrade\": True,\n",
    "                    \"safebrowsing_for_trusted_sources_enabled\": False,\n",
    "                    \"safebrowsing.enabled\": False\n",
    "            })\n",
    "            chrome_options.add_argument('--disable-gpu')\n",
    "            chrome_options.add_argument('--disable-software-rasterizer')\n",
    "            ua = UserAgent(family='chrome')\n",
    "            randomua = ua.random()\n",
    "            chrome_options.add_argument(f'user-agent={randomua}')\n",
    "        return chrome_options\n",
    "\n",
    "            \n",
    "\n",
    "class SeleniumPage:\n",
    "\n",
    "    def __init__(self, driver):\n",
    "        self.driver = driver\n",
    "\n",
    "    def fill_form_field(self, locator_name, value):\n",
    "        element = self._get_element_by_locator(locator_name)\n",
    "        element.send_keys(value + Keys.RETURN)\n",
    "       #element.send_keys(value)\n",
    "    def nick_fill_form_field(self, locator_name, value):\n",
    "        element = self._get_element_by_locator(locator_name)\n",
    "        element.send_keys(value)\n",
    "        \n",
    "    def click(self, locator_name):\n",
    "        element = self._get_element_by_locator(locator_name)\n",
    "        element.click()\n",
    "        \n",
    "    def fill_calendar(self,locator_name, value):\n",
    "        element = self._get_element_by_locator(locator_name)\n",
    "        self.driver.execute_script(\"arguments[0].removeAttribute('readonly','readonly')\",element)\n",
    "        element.send_keys(Keys.CONTROL + \"a\")\n",
    "        element.send_keys(Keys.DELETE)\n",
    "        element.send_keys(value)\n",
    "\n",
    "    def _get_element_by_locator(self, locator_name):\n",
    "        #deleting self.locators because Im pretty sure it isnt needed\n",
    "        #locator = getattr(self.locators, locator_name)\n",
    "        #locator = getattr(locator_name)\n",
    "        return self.driver.find_element(*locator_name)\n",
    "    \n",
    "    def _get_elements_by_locator(self, locator_name):\n",
    "        #locator = getattr(self.locators, locator_name)\n",
    "        return self.driver.find_elements(*locator_name)\n",
    "    \n",
    "    def nick_get_html(self, driver):\n",
    "        self.driver = driver\n",
    "        data = driver.page_source\n",
    "        #print(data.url)\n",
    "        print(\"done\")\n",
    "        return data\n",
    "\n",
    "    def nick_save_html(self, data, filename):\n",
    "        self.file = open(filename, \"a\")\n",
    "        self.file.write(data)\n",
    "        self.file.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "#from anticaptchaofficial.recaptchav2proxyless import *\n",
    "from selenium.webdriver.support import expected_conditions as EC\n",
    "from selenium.webdriver.support.ui import WebDriverWait\n",
    "import time\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "from selenium.webdriver.common.by import By\n",
    "class HillsboroughURLs:\n",
    "      \n",
    "    CASE_SEARCH = 'https://hover.hillsclerk.com/html/case/caseSearch.html'\n",
    "class HillsboroughVariables:\n",
    "    \n",
    "    USERNAME = \""\n",
    "    PASSWORD = \"\"\n",
    "    \n",
    "\n",
    "class CaptchaLocators:\n",
    "\n",
    "    #CAPTCHA = (By.XPATH, '/html/body/div[2]')\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "class HillsboroughBasePage(SeleniumPage):\n",
    "    \n",
    "    #captcha = InvisibleRecaptchaV2()\n",
    "    variables = HillsboroughVariables()\n",
    "    \n",
    "    def __init__(self, driver, url):\n",
    "        super().__init__(driver)\n",
    "        self.site_url = url\n",
    "    \n",
    "    def go_to(self):\n",
    "        self.driver.get(self.site_url)\n",
    "        time.sleep(1)\n",
    "    \"\"\"\n",
    "    def test_captcha(self):\n",
    "        return self.captcha.test(self.driver, self.locators.CAPTCHA[1])\n",
    "        \n",
    "        \n",
    "    def solve_captcha(self):\n",
    "        self.captcha.solve(\n",
    "            self.driver, self.variables.SITEKEY, self.variables.APIKEY, \n",
    "            self.locators.CAPTCHA[1],  self.variables.CALLBACK_FUNCTION\n",
    "        )\n",
    "    \"\"\"     \n",
    "    def save_cookies(self):\n",
    "        #pickle.dump(self.driver.get_cookies(), open(f'{cache_dir}/cookies.pkl', 'wb'))\n",
    "        pickle.dump(self.driver.get_cookies(), open(f'cookies.pkl', 'wb'))\n",
    "    \n",
    "    def load_cookies(self):\n",
    "        #cookies = pickle.load(open(f'{cache_dir}/cookies.pkl', 'rb'))\n",
    "        cookies = pickle.load(open(f'cookies.pkl', 'rb'))\n",
    "        for cookie in cookies:\n",
    "                self.driver.add_cookie(cookie)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "from selenium.webdriver.common.by import By\n",
    "import pickle\n",
    "\n",
    "\n",
    "class CaseDetailsLocators:\n",
    "    \n",
    "    CAPTCHA = (By.XPATH, '/html/body/div[2]')\n",
    "\n",
    "class CaseDetails(HillsboroughBasePage):\n",
    "       \n",
    "    locators = CaseDetailsLocators()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SearchPageMixIn():\n",
    "\n",
    "    lastdate = LastDate()\n",
    "\n",
    "    def _county_specific_selenium_search(self):\n",
    "        raise CountyNotSupported('County is not supported. Are you a developer? Did you forget to provide county-specific steps for searching?')\n",
    "    \n",
    "    def _get_last_workday(self, subtract_days = 1):\n",
    "        self.subtract_days = subtract_days\n",
    "        self.url_date = self.lastdate.date_to_search(self.year, subtract_days = subtract_days).strftime(\"%m/%d/%Y\")\n",
    "\n",
    "    def _subtract_another_day(self, subtract_days = 1):\n",
    "        self.subtract_days = self.subtract_days + subtract_days\n",
    "\n",
    "    def _parse_case_table(self):\n",
    "        \n",
    "       \n",
    "        rows = self.driver.find_elements(By.XPATH, '//*[@id=\"mycasesdata\"]/tbody/tr')\n",
    "        row_number = len(rows)\n",
    "        #print(f'row number: {row_number}')\n",
    "        self.case_number = self.driver.find_element(By.XPATH, f'//*[@id=\"mycasesdata\"]/tbody/tr[{row_number}]/td[2]').text\n",
    "        #print(self.case_number)\n",
    "        if self.case_number[0:3] != self.empty_return_text and self.case_number != None:\n",
    "            return self.case_number\n",
    "        elif self.single_case_result != None:\n",
    "            return self.single_case_result\n",
    "        else:\n",
    "            raise IndexError()\n",
    "\n",
    "    def _search_previous_day_until_success(self):\n",
    "        result = None\n",
    "        while result is None:\n",
    "            try:\n",
    "                print('subtracting another day')\n",
    "                self._subtract_another_day()\n",
    "                print('getting next workday')\n",
    "                self._get_last_workday(subtract_days = self.subtract_days)\n",
    "                print('calling new html search')\n",
    "                if self.driver != None:\n",
    "                    self._county_specific_selenium_steps()\n",
    "                else:\n",
    "                    self.output = self.get_html(self.url, payload = self.payload)\n",
    "                print(f'attempting to parse case table for {self.url_date}')\n",
    "                result = self._parse_case_table()\n",
    "            except IndexError:\n",
    "                pass  \n",
    "        return result\n",
    "\n",
    "    def most_recent_case(self, year,case_prefix,county = None,  session=None, driver=None, row_locator=None, single_case_locator=None, empty_return_text=None):\n",
    "        self.county = county\n",
    "        self.year = year\n",
    "        self.case_prefix = case_prefix\n",
    "        self.driver = driver\n",
    "        self.row_locator = row_locator\n",
    "        self.single_case_locator = single_case_locator\n",
    "        self.session = session\n",
    "        self.empty_return_text = empty_return_text\n",
    "        self._get_last_workday()\n",
    "        if self.driver != None:\n",
    "            \n",
    "            self._county_specific_selenium_steps()\n",
    "        else:\n",
    "            self.output = self.get_html(self.url, payload = self.payload) \n",
    "        try:\n",
    "            \n",
    "            #print(self._parse_case_table())\n",
    "            return self._parse_case_table()\n",
    "        except:\n",
    "            \n",
    "            return self._search_previous_day_until_success()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# because of the inherent relationship between search pages and search results page during page discovery,\n",
    "# i propose that we think of the two as one object that can handle both sides of the page\n",
    "\n",
    "from selenium.webdriver.common.keys import Keys\n",
    "\n",
    "class SearchLocators:\n",
    "    \n",
    "    LOGIN = (By.XPATH, \"/html/body/nav/nav/div[2]/ul[3]/li/a\")\n",
    "    USERNAME_FIELD = (By.XPATH,\"/html/body/div[3]/div[3]/div[2]/div/form/div[1]/div/input\" )\n",
    "    PASSWORD_FIELD = (By.XPATH,\"/html/body/div[3]/div[3]/div[2]/div/form/div[2]/div/input\" )\n",
    "    LOGIN2 = (By.ID, \"login\")\n",
    "    \n",
    "\n",
    "    ##Single Case INfo\n",
    "\n",
    "    SINGLE_CASE_SEARCH = (By.XPATH,'/html/body/div[4]/div[3]/div/div[1]/div/div[1]/input' )\n",
    "\n",
    "    BETWEEN_DATES = (By.XPATH,'//*[contains(text(), \"Search by a date range / court type / case type\")]/parent::node()')\n",
    "    CASE_CATEGORY = (By.XPATH, '//*[contains(text(), \"CIVIL\")]')\n",
    "    CASE_TYPE = (By.XPATH, '/html/body/div[4]/div[3]/div/div[3]/div[3]/div[2]/select/option[114]')\n",
    "    DATE_AFTER = (By.ID,\"dateFiledAfter\" )\n",
    "    DATE_BEFORE = (By.ID, 'dateFiledBefore')\n",
    "    SUBMIT = (By.ID, 'submitCaseSearch')\n",
    "    \n",
    "    \n",
    "    ##tabs for html\n",
    "    EVENTS_TAB =  (By.ID, \"lblCaseEvents\")\n",
    "    JUDGEMENTS_TAB = (By.ID, \"lblCaseJudgments\")\n",
    "    \n",
    "    \n",
    "class ResultsLocators:\n",
    "    \n",
    "    \n",
    "    RESULTS_TABLE = (By.XPATH, '//*[@id=\"mycasesdata\"]/tbody')\n",
    "    RESULTS_TABLE_ROWS = (By.XPATH, '//*[@id=\"mycasesdata\"]/tbody/tr')\n",
    "    EMPTY_RETURN = 'No'\n",
    "    SINGLE_CASE_RETURN = None\n",
    "    \n",
    "    #####Tabs\n",
    "    EVENTS_TABLE = (By.XPATH, '//*[@id=\"eventsTable\"]/tbody')\n",
    "    JUDGEMENT_TABLE = (By.XPATH, '//*[@id=\"judgmentsdata\"]/tbody')\n",
    "\n",
    "class SearchPage(HillsboroughBasePage, SearchPageMixIn):\n",
    "    \n",
    "    search = SearchLocators()\n",
    "    results = ResultsLocators()\n",
    "    urls = HillsboroughURLs()\n",
    "    variables = HillsboroughVariables()\n",
    "\n",
    "    def _county_specific_selenium_steps(self):\n",
    "        self.go_to()\n",
    "        \n",
    "        try:\n",
    "            LOGIN_STATUS = self.driver.find_element(By.XPATH, \"/html/body/nav/nav/div[2]/ul[3]/li/a\").text\n",
    "            if \"Login\" in LOGIN_STATUS:\n",
    "                print(\"LOGGING IN\")\n",
    "                self.click(self.search.LOGIN)\n",
    "                time.sleep(3)\n",
    "\n",
    "                #enter login credentials\n",
    "                self.nick_fill_form_field(self.search.USERNAME_FIELD, self.variables.USERNAME)\n",
    "                self.nick_fill_form_field(self.search.PASSWORD_FIELD, self.variables.PASSWORD)\n",
    "                time.sleep(1)\n",
    "                #login\n",
    "                self.click(self.search.LOGIN2)\n",
    "                time.sleep(2)\n",
    "        except:\n",
    "            print(\"Already Loggged in\")\n",
    "            \n",
    "        self.click(self.search.BETWEEN_DATES)\n",
    "        self.click(self.search.CASE_CATEGORY)\n",
    "        time.sleep(3)\n",
    "        self.click(self.search.CASE_TYPE)\n",
    "        print(f'the date is {self.url_date}')\n",
    "        self.fill_calendar(self.search.DATE_AFTER,self.url_date)\n",
    "        self.fill_calendar(self.search.DATE_BEFORE,self.url_date)\n",
    "        time.sleep(.2)\n",
    "        self.click(self.search.SUBMIT)\n",
    "        try:\n",
    "            WebDriverWait(self.driver, 10).until(\n",
    "                EC.element_to_be_clickable(\n",
    "                    self.results.RESULTS_TABLE)\n",
    "            )\n",
    "        except:\n",
    "            pass\n",
    "        #time.sleep(3)\n",
    "        \n",
    "    def _county_specific_selenium_steps2(self, DATE_AFTER, DATE_BEFORE):\n",
    "        \n",
    "        self.DATE_AFTER = DATE_AFTER\n",
    "        self.DATE_BEFORE = DATE_BEFORE\n",
    "        self.go_to()\n",
    "        \n",
    "        try:\n",
    "            LOGIN_STATUS = self.driver.find_element(By.XPATH, \"/html/body/nav/nav/div[2]/ul[3]/li/a\").text\n",
    "            if \"Login\" in LOGIN_STATUS:\n",
    "                print(\"LOGGING IN\")\n",
    "                self.click(self.search.LOGIN)\n",
    "                time.sleep(3)\n",
    "\n",
    "                #enter login credentials\n",
    "                self.nick_fill_form_field(self.search.USERNAME_FIELD, self.variables.USERNAME)\n",
    "                self.nick_fill_form_field(self.search.PASSWORD_FIELD, self.variables.PASSWORD)\n",
    "                time.sleep(1)\n",
    "                #login\n",
    "                self.click(self.search.LOGIN2)\n",
    "                time.sleep(2)\n",
    "        except:\n",
    "            print(\"Already Loggged in\")\n",
    "            \n",
    "        self.click(self.search.BETWEEN_DATES)\n",
    "        self.click(self.search.CASE_CATEGORY)\n",
    "        time.sleep(3)\n",
    "        self.click(self.search.CASE_TYPE)\n",
    "        #print(f'the date is {self.url_date}')\n",
    "        self.fill_calendar(self.search.DATE_AFTER,self.DATE_AFTER)\n",
    "        self.fill_calendar(self.search.DATE_BEFORE,self.DATE_BEFORE)\n",
    "        time.sleep(.2)\n",
    "        self.click(self.search.SUBMIT)\n",
    "        try:\n",
    "            WebDriverWait(self.driver, 10).until(\n",
    "                EC.element_to_be_clickable(\n",
    "                    self.results.RESULTS_TABLE)\n",
    "            )\n",
    "        except:\n",
    "            pass\n",
    "        rows = self.driver.find_elements(By.XPATH, '//*[@id=\"mycasesdata\"]/tbody/tr')\n",
    "        row_number = len(rows)\n",
    "        print(f'how many rows there are: {row_number}')\n",
    "        if row_number <500:\n",
    "            \n",
    "            for case in range(1,4):\n",
    "                self.case_number = self.driver.find_element(By.XPATH, f'//*[@id=\"mycasesdata\"]/tbody/tr[{case}]/td[2]').text\n",
    "                magnifying_glass = (By.XPATH, f'//*[@id=\"mycasesdata\"]/tbody/tr[{case}]/td[1]/button[1]')\n",
    "                self.click(magnifying_glass)\n",
    "                windowHandles = self.driver.window_handles\n",
    "                print(f'row number: {case} and case id: {self.case_number}')\n",
    "                self.driver.switch_to.window(windowHandles[case])\n",
    "                time.sleep(.2)\n",
    "                self.nick_save_html(self.nick_get_html(self.driver), self.case_number)\n",
    "                self.driver.switch_to.window(windowHandles[0])\n",
    "        else:\n",
    "            return(False)\n",
    "            \n",
    "       \n",
    "        \n",
    "        #time.sleep(3)\n",
    "    def _county_specific_selenium_steps_single_search(self, case_id):\n",
    "        self.go_to() \n",
    "        self.case_id = case_id\n",
    "        try:\n",
    "            LOGIN_STATUS = self.driver.find_element(By.XPATH, \"/html/body/nav/nav/div[2]/ul[3]/li/a\").text\n",
    "            if \"Login\" in LOGIN_STATUS:\n",
    "                print(\"LOGGING IN\")\n",
    "                self.click(self.search.LOGIN)\n",
    "                time.sleep(3)\n",
    "\n",
    "                #enter login credentials\n",
    "                self.nick_fill_form_field(self.search.USERNAME_FIELD, self.variables.USERNAME)\n",
    "                self.nick_fill_form_field(self.search.PASSWORD_FIELD, self.variables.PASSWORD)\n",
    "                time.sleep(1)\n",
    "                #login\n",
    "                self.click(self.search.LOGIN2)\n",
    "                time.sleep(2)\n",
    "        except:\n",
    "            print(\"Already Loggged in\")\n",
    "            \n",
    "            \n",
    "            \n",
    "        self.fill_form_field(self.search.SINGLE_CASE_SEARCH,self.case_id)\n",
    "        time.sleep(.2)\n",
    "        \n",
    "        try:\n",
    "            WebDriverWait(self.driver, 10).until(\n",
    "                EC.element_to_be_clickable(\n",
    "                    self.results.RESULTS_TABLE)\n",
    "            )\n",
    "        except:\n",
    "            pass\n",
    "        rows = self.driver.find_elements(By.XPATH, '//*[@id=\"mycasesdata\"]/tbody/tr')\n",
    "        row_number = len(rows)\n",
    "        magnifying_glass = (By.XPATH, f'//*[@id=\"mycasesdata\"]/tbody/tr[{row_number}]/td[1]/button[1]')\n",
    "        self.click(magnifying_glass)\n",
    "        windowHandles = self.driver.window_handles\n",
    "        self.driver.switch_to.window(windowHandles[1])\n",
    "        time.sleep(3)\n",
    "        self.nick_save_html(self.nick_get_html(self.driver), self.case_id)\n",
    "        \n",
    "    def str_to_date(self,str_date):\n",
    "        u = datetime.strptime(str_date,\"%m/%d/%Y\").date()\n",
    "        return(u)\n",
    "\n",
    "    def date_to_str(self,obj_date):\n",
    "        u = obj_date.strftime(\"%m/%d/%Y\")\n",
    "        return(u)\n",
    "        \n",
    "    def final_scrape_id(self, DATE_AFTER, DATE_BEFORE, _days):\n",
    "        parse = Parser()\n",
    "        self.DATE_AFTER = DATE_AFTER\n",
    "        self.DATE_BEFORE = DATE_BEFORE\n",
    "        self.go_to()\n",
    "        ls_case_name = []\n",
    "        progress_date = []\n",
    "\n",
    "        start_date = DATE_AFTER\n",
    "        end_date = DATE_BEFORE\n",
    "        start = DATE_AFTER\n",
    "\n",
    "        progress_date.append(start_date)\n",
    "        print(f'first print of list: {progress_date}')\n",
    "\n",
    "        count = 0\n",
    "\n",
    "        while self.str_to_date(start) <= self.str_to_date(end_date):\n",
    "            count = count +1\n",
    "            try:\n",
    "                LOGIN_STATUS = self.driver.find_element(By.XPATH, \"/html/body/nav/nav/div[2]/ul[3]/li/a\").text\n",
    "                if \"Login\" in LOGIN_STATUS:\n",
    "                    print(\"LOGGING IN\")\n",
    "                    self.click(self.search.LOGIN)\n",
    "                    time.sleep(3)\n",
    "\n",
    "                    #enter login credentials\n",
    "                    self.nick_fill_form_field(self.search.USERNAME_FIELD, self.variables.USERNAME)\n",
    "                    self.nick_fill_form_field(self.search.PASSWORD_FIELD, self.variables.PASSWORD)\n",
    "                    time.sleep(1)\n",
    "                    #login\n",
    "                    self.click(self.search.LOGIN2)\n",
    "                    time.sleep(2)\n",
    "            except:\n",
    "                print(\"Already Loggged in\")\n",
    "\n",
    "            self.click(self.search.BETWEEN_DATES)\n",
    "            self.click(self.search.CASE_CATEGORY)\n",
    "            time.sleep(3)\n",
    "            self.click(self.search.CASE_TYPE)\n",
    "            #print(f'the date is {self.url_date}')\n",
    "            if count == 1:\n",
    "                d = timedelta(days=_days)\n",
    "                print(f'delta is {d} and last element in list is {progress_date[-1]}')\n",
    "                t = self.str_to_date(progress_date[-1]) + d\n",
    "                progress_date.append(self.date_to_str(t))\n",
    "                end = progress_date[-1]\n",
    "                self.fill_calendar(self.search.DATE_AFTER,start_date)\n",
    "                self.fill_calendar(self.search.DATE_BEFORE,end)\n",
    "                print(f'FIRST ROUND: start: {start_date} -- end: {end}')\n",
    "            else:\n",
    "                if self.str_to_date(end) > self.str_to_date(end_date):\n",
    "                    end = end_date\n",
    "                self.fill_calendar(self.search.DATE_AFTER,start)\n",
    "                self.fill_calendar(self.search.DATE_BEFORE,end)\n",
    "                print(f'After first round: start: {start} -- end: {end}')\n",
    "            time.sleep(.2)\n",
    "            self.click(self.search.SUBMIT)\n",
    "            try:\n",
    "                WebDriverWait(self.driver, 10).until(\n",
    "                    EC.element_to_be_clickable(\n",
    "                        self.results.RESULTS_TABLE)\n",
    "                )\n",
    "            except:\n",
    "                pass\n",
    "            rows = self.driver.find_elements(By.XPATH, '//*[@id=\"mycasesdata\"]/tbody/tr')\n",
    "            row_number = len(rows)\n",
    "            print(\"+++++++++\")\n",
    "            print(f'how many rows there are: {row_number}')\n",
    "            print(\"+++++++++\")\n",
    "            if row_number <500:\n",
    "                \n",
    "\n",
    "                for case in range(1,row_number+1):\n",
    "                    self.case_number = self.driver.find_element(By.XPATH, f'//*[@id=\"mycasesdata\"]/tbody/tr[{case}]/td[2]').text\n",
    "                    ls_case_name.append(self.case_number)\n",
    "                    #print(f'row number: {case} and case id: {self.case_number}')                  \n",
    "                \n",
    "                \n",
    "                \n",
    "               \n",
    "                    \n",
    "                ###adds 7 days to the first date and adds to list\n",
    "                d_end = timedelta(days=_days)\n",
    "                t_end = self.str_to_date(progress_date[-1]) + d_end\n",
    "                progress_date.append(self.date_to_str(t_end))\n",
    "                ###### makes next start date the second to last start + 1, \n",
    "                d_start = timedelta(days=1)\n",
    "                start = self.date_to_str(self.str_to_date(progress_date[-2])+d_start )\n",
    "                end = progress_date[-1]                              \n",
    "                \n",
    "                \n",
    "                \n",
    "            else:\n",
    "                print(\"subtracting a day ---------\")\n",
    "                #replaces last date with the last date -1\n",
    "                current = progress_date.pop()\n",
    "                d_end = timedelta(days=1)\n",
    "                progress_date.append(self.date_to_str(self.str_to_date(current) - d_end))\n",
    "                \n",
    "                #makes next start date the second to last start + 1, \n",
    "                d_start = timedelta(days=1)\n",
    "                start = self.date_to_str(self.str_to_date(progress_date[-2])+d_start)\n",
    "                end = progress_date[-1]\n",
    "                #print(f'range is from {start} to {end}')\n",
    "                \n",
    "            print(\"----------------------NEW WEEK SPAN----------------------------------\")\n",
    "            \n",
    "            \n",
    "            self.go_to()\n",
    "        print(\"+++++++++++++++++++DONE+++++++++++++++++++++++++++++++++\")\n",
    "        dict_case_id = {'case_id': ls_case_name}       \n",
    "        df = pd.DataFrame(dict_case_id)   \n",
    "        # saving the dataframe \n",
    "        df.to_csv('case_ids.csv') \n",
    "        \n",
    "    def final_scrape(self, ls_ids, start_num, end_num):\n",
    "        parse = Parser()        \n",
    "        self.go_to()\n",
    "        ls_sample_id = ls_ids[start_num:end_num+1]\n",
    "        for case in ls_sample_id:\n",
    "                    \n",
    "        \n",
    "            try:\n",
    "                LOGIN_STATUS = self.driver.find_element(By.XPATH, \"/html/body/nav/nav/div[2]/ul[3]/li/a\").text\n",
    "                if \"Login\" in LOGIN_STATUS:\n",
    "                    print(\"LOGGING IN\")\n",
    "                    self.click(self.search.LOGIN)\n",
    "                    time.sleep(3)\n",
    "\n",
    "                    #enter login credentials\n",
    "                    self.nick_fill_form_field(self.search.USERNAME_FIELD, self.variables.USERNAME)\n",
    "                    self.nick_fill_form_field(self.search.PASSWORD_FIELD, self.variables.PASSWORD)\n",
    "                    time.sleep(1)\n",
    "                    #login\n",
    "                    self.click(self.search.LOGIN2)\n",
    "                    time.sleep(2)\n",
    "            except:\n",
    "                print(\"Already Loggged in\")\n",
    "\n",
    "            self.fill_form_field(self.search.SINGLE_CASE_SEARCH,case)\n",
    "            \n",
    "            try:\n",
    "                WebDriverWait(self.driver, 10).until(\n",
    "                    EC.element_to_be_clickable(\n",
    "                        self.results.RESULTS_TABLE)\n",
    "                )\n",
    "            except:\n",
    "                pass\n",
    "            rows = self.driver.find_elements(By.XPATH, '//*[@id=\"mycasesdata\"]/tbody/tr')\n",
    "            row_number = len(rows)\n",
    "            print(\"+++++++++\")\n",
    "            print(f'how many rows there are: {row_number}')\n",
    "            print(\"+++++++++\")\n",
    "\n",
    "            ls_case_name = []\n",
    "\n",
    "            for case in range(1,row_number+1):\n",
    "                self.case_number = self.driver.find_element(By.XPATH, f'//*[@id=\"mycasesdata\"]/tbody/tr[{case}]/td[2]').text\n",
    "                ls_case_name.append(self.case_number)\n",
    "                print(f'row number: {case} and case id: {self.case_number}')\n",
    "                magnifying_glass = (By.XPATH, f'//*[@id=\"mycasesdata\"]/tbody/tr[{case}]/td[1]/button[1]')                    \n",
    "                self.click(magnifying_glass)\n",
    "\n",
    "            windowHandles = self.driver.window_handles\n",
    "\n",
    "            for window in range(1,len(windowHandles)):\n",
    "\n",
    "\n",
    "                self.driver.switch_to.window(windowHandles[window])\n",
    "\n",
    "                try:\n",
    "                    self.click(self.search.EVENTS_TAB)\n",
    "                    try:\n",
    "                        WebDriverWait(self.driver, 10).until(\n",
    "                            EC.element_to_be_clickable(\n",
    "                                self.results.EVENTS_TABLE)\n",
    "                        )\n",
    "                    except:\n",
    "                        pass\n",
    "                except:\n",
    "                    pass\n",
    "\n",
    "                id_name_save = ls_case_name.pop()\n",
    "                self.nick_save_html(self.nick_get_html(self.driver), id_name_save)\n",
    "                print(f'{self.case_number} was saved')\n",
    "                self.driver.close()\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "                windowHandles = self.driver.window_handles\n",
    "                self.driver.switch_to.window(windowHandles[0])\n",
    "\n",
    "                self.go_to()\n",
    "        print(\"+++++++++++++++++++DONE+++++++++++++++++++++++++++++++++\")\n",
    "    def most_recent_case(self, year, case_prefix):\n",
    "        return super().most_recent_case(year, case_prefix, county = None, session=None, driver=self.driver, row_locator=self.results.RESULTS_TABLE_ROWS, single_case_locator=self.results.SINGLE_CASE_RETURN, empty_return_text=self.results.EMPTY_RETURN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Parser():\n",
    "    def __init__(self):\n",
    "        self.lxml_parser = etree.HTMLParser()\n",
    "\n",
    "    \n",
    "    def open_html(self, html_file):\n",
    "        self.html_file = html_file\n",
    "        self.html = open(self.html_file, \"r\")\n",
    "        self.html = self.html.read()\n",
    "        #lxml will not access text after <br> tags and xpaths to their location return nothing, thus removal solves the problem with no known drawbacks\n",
    "        #self.html = self.html.replace('<br>', ' ')\n",
    "        #print(self.html)\n",
    "        return etree.parse(StringIO(self.html), self.lxml_parser)\n",
    "    \n",
    "    def _get_info(self, location):\n",
    "        self.location = location\n",
    "        #print(\"+++++++\")\n",
    "        #print(self.tree.xpath(f'{self.location}//text()'))\n",
    "        #print(\"++++++++\")\n",
    "        return self.tree.xpath(self.location)\n",
    "    \"\"\"\n",
    "    def _get_info2(self, location):\n",
    "        self.location = location\n",
    "        #print(\"+++++++\")\n",
    "        #print(self.tree.xpath(f'{self.location}//text()'))\n",
    "        #print(\"++++++++\")\n",
    "        return self.tree.xpath(f'{self.location}//text()')\n",
    "    \"\"\"\n",
    "    \n",
    "    def clean(self, dirty):\n",
    "        self.dirty = dirty\n",
    "        self.dirty = self.dirty.lower().strip().replace('\\n', '')\n",
    "        return self.dirty\n",
    "\n",
    "    def find_element_by_xpath(self, location):\n",
    "        self.info = self._get_info(location)\n",
    "        \n",
    "        if isinstance(self.info, list):\n",
    "            if len(self.info) == 0:\n",
    "                #print('length is 0')\n",
    "                return 'none'\n",
    "            elif self.info[0].text != None and self.clean(self.info[0].text) != '':\n",
    "                #print('position 1 is not none')\n",
    "                return self.clean(self.info[0].text)\n",
    "            else:\n",
    "                #print('should be returning string of none')\n",
    "                return 'none'\n",
    "        elif self.info == None:\n",
    "            #print('not a list, is none')\n",
    "            return 'none'\n",
    "        else:\n",
    "            #print('not a list, not none')\n",
    "            return self.info\n",
    "    \n",
    "    def find_elements_by_xpath(self, location):\n",
    "        self.info = self._get_info(location)\n",
    "        return self.info\n",
    "        if isinstance(self.info, list):\n",
    "            if len(self.info) == 1:\n",
    "                raise ElementException('Element only returned one element. Try find_element_by_xpath (singular)')\n",
    "            else:\n",
    "                return self.info\n",
    "        else:\n",
    "            raise ElementException('Element only returned one element. Try find_element_by_xpath (singular).')\n",
    "    \n",
    "    #counts elements returned by find_elements_by_xpath, returns number\n",
    "    def get_length_by_xpath(self, location):\n",
    "        self.info = self._get_info(location)\n",
    "        return len(self.info)\n",
    "    \n",
    "    # this function writes multiples 'none's to a given list until that list is 3 items long\n",
    "    def expand_list(self, list, length):\n",
    "        self.list = list\n",
    "        self.length = length\n",
    "        while len(self.list) < self.length:\n",
    "            try:\n",
    "                self.list.append('none')\n",
    "            except:\n",
    "                pass\n",
    "        return self.list\n",
    "\n",
    "    def more_than(self, list, count):\n",
    "        self.list = list\n",
    "        self.count = count\n",
    "        if len(self.list) > self.count:\n",
    "            return 'yes'\n",
    "        else:\n",
    "            return 'no'\n",
    "        \n",
    "    def text_between(self, text, before, after):\n",
    "        self.text = text\n",
    "        self.before = before\n",
    "        self.after = after\n",
    "        try:\n",
    "            self.parse = self.text.split(self.before)\n",
    "            self.parse = self.parse[1].split(self.after)\n",
    "            self.parse = self.clean(self.parse[0])\n",
    "        except:\n",
    "            self.parse = 'none'\n",
    "        return self.parse\n",
    "\n",
    "    def does_string_appear(self, text, string):\n",
    "        self.text = text\n",
    "        self.string = string\n",
    "        self.test = self.text.find(self.string)\n",
    "        if self.test != -1:\n",
    "            return 'yes'\n",
    "        else:\n",
    "            return 'no'\n",
    "    \n",
    "    #this function provides an entry_point to the best xpath logic for new users\n",
    "    #it follows this logic{div/table item is in}/{div/html element text is in}/{text to search}/{xpath to follow to get to relative field}\n",
    "    def string_search(self, text, table, route=None, text_location=None):\n",
    "        self.text = text\n",
    "        self.table = table\n",
    "        self.route = route\n",
    "        self.text_location = text_location\n",
    "        if self.text_location == None and self.route == None:\n",
    "            #('no location and no route')\n",
    "            return self.find_element_by_xpath(f'{self.table}//*[contains(text(), \"{text}\")]')\n",
    "        elif self.text_location == None and self.route != None:\n",
    "            #('no location')\n",
    "            return self.find_element_by_xpath(f'{self.table}//*[contains(text(), \"{text}\")]/{self.route}')\n",
    "        elif self.text_location != None and self.route == None:\n",
    "            #('no route')\n",
    "            return self.find_element_by_xpath(f'{self.table}//{self.text_location}[contains(text(), \"{text}\")]')\n",
    "        elif self.text_location != None and self.route != None:\n",
    "            #('location and route')\n",
    "            return self.find_element_by_xpath(f'{self.table}//{self.text_location}[contains(text(), \"{text}\")]/{self.route}')\n",
    "    \n",
    "    \n",
    "    # this function creates a new database and failure log but wont overwrite existing one\n",
    "    def create_csv(self, database_name, header):\n",
    "        self.database_name = database_name\n",
    "        self.header = header\n",
    "        self.file = f'{file_path}/{self.database_name}'\n",
    "        if path.exists(self.file):\n",
    "            print('CSV already exists.')\n",
    "        else:\n",
    "            with open(self.file, 'w', newline='') as self.outfile:\n",
    "                self.writer = csv.writer(self.outfile)\n",
    "                self.writer.writerow(self.header)\n",
    "            print('New CSV created.')\n",
    "    \n",
    "    def write_data(self, data_out, database_name):\n",
    "        #writing data to csv\n",
    "        self.data_out = data_out\n",
    "        self.database_name = database_name\n",
    "        self.file = f'{file_path}/{self.database_name}'\n",
    "        with open(self.file, 'a', newline='') as self.outfile:\n",
    "            self.writer = csv.writer(self.outfile, delimiter=',')\n",
    "            self.writer.writerow(self.data_out)\n",
    "            \n",
    "    def write_json_data(self, data_out, database_name):\n",
    "        #writing data to json\n",
    "        self.data_out = data_out\n",
    "        self.database_name = database_name\n",
    "        self.file = f'{file_path}/{self.database_name}'\n",
    "        with open(self.file, 'w') as self.outfile:\n",
    "            json.dump(self.data_out, self.outfile)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "scraper = 1\n",
    "column_names = [\"case_id\"]\n",
    "df = pd.read_csv(\"case_ids.csv\", names = column_names)\n",
    "ls = df.case_id.to_list()\n",
    "\n",
    "if scraper == 1:\n",
    "    a=0\n",
    "    b=800\n",
    "elif scraper == 2:\n",
    "    a=801\n",
    "    b=1601\n",
    "elif scraper == 3:\n",
    "    a= 1602\n",
    "    b=2402\n",
    "elif scraper ==5:\n",
    "    a=2403\n",
    "    b=3203\n",
    "elif scraper ==6:\n",
    "    a=3204\n",
    "    b=4004\n",
    "elif scraper ==7:\n",
    "    a=4005\n",
    "    b=4805\n",
    "elif scraper ==8:\n",
    "    a=4806\n",
    "    b=5606\n",
    "elif scraper ==9:\n",
    "    a=5607\n",
    "    b=6407\n",
    "elif scraper ==10:\n",
    "    a=6407\n",
    "    b=7964\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "test = SeleniumSite()\n",
    "test_driver = test._init_chrome_driver(headless=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "first print of list: ['01/01/2020']\n",
      "LOGGING IN\n",
      "delta is 14 days, 0:00:00 and last element in list is 01/01/2020\n",
      "FIRST ROUND: start: 01/01/2020 -- end: 01/15/2020\n",
      "+++++++++\n",
      "how many rows there are: 460\n",
      "+++++++++\n",
      "----------------------NEW WEEK SPAN----------------------------------\n",
      "Already Loggged in\n",
      "After first round: start: 01/16/2020 -- end: 01/29/2020\n",
      "+++++++++\n",
      "how many rows there are: 500\n",
      "+++++++++\n",
      "subtracting a day ---------\n",
      "----------------------NEW WEEK SPAN----------------------------------\n",
      "Already Loggged in\n",
      "After first round: start: 01/16/2020 -- end: 01/28/2020\n",
      "+++++++++\n",
      "how many rows there are: 500\n",
      "+++++++++\n",
      "subtracting a day ---------\n",
      "----------------------NEW WEEK SPAN----------------------------------\n",
      "Already Loggged in\n",
      "After first round: start: 01/16/2020 -- end: 01/27/2020\n",
      "+++++++++\n",
      "how many rows there are: 436\n",
      "+++++++++\n",
      "----------------------NEW WEEK SPAN----------------------------------\n",
      "Already Loggged in\n",
      "After first round: start: 01/28/2020 -- end: 02/10/2020\n",
      "+++++++++\n",
      "how many rows there are: 445\n",
      "+++++++++\n",
      "----------------------NEW WEEK SPAN----------------------------------\n",
      "Already Loggged in\n",
      "After first round: start: 02/11/2020 -- end: 02/24/2020\n",
      "+++++++++\n",
      "how many rows there are: 500\n",
      "+++++++++\n",
      "subtracting a day ---------\n",
      "----------------------NEW WEEK SPAN----------------------------------\n",
      "Already Loggged in\n",
      "After first round: start: 02/11/2020 -- end: 02/23/2020\n",
      "+++++++++\n",
      "how many rows there are: 499\n",
      "+++++++++\n",
      "----------------------NEW WEEK SPAN----------------------------------\n",
      "Already Loggged in\n",
      "After first round: start: 02/24/2020 -- end: 02/27/2020\n",
      "+++++++++\n",
      "how many rows there are: 177\n",
      "+++++++++\n",
      "----------------------NEW WEEK SPAN----------------------------------\n",
      "+++++++++++++++++++DONE+++++++++++++++++++++++++++++++++\n"
     ]
    }
   ],
   "source": [
    "\n",
    "searchpage = SearchPage(test_driver, 'https://hover.hillsclerk.com/html/case/caseSearch.html')\n",
    "#searchpage.most_recent_case(2020, 'CC')\n",
    "searchpage.final_scrape_id(\"01/01/2020\",\"02/27/2020\", 14)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LOGGING IN\n",
      "+++++++++\n",
      "how many rows there are: 1\n",
      "+++++++++\n",
      "row number: 1 and case id: 20-CC-000808\n",
      "done\n",
      "20-CC-000808 was saved\n",
      "Already Loggged in\n",
      "+++++++++\n",
      "how many rows there are: 1\n",
      "+++++++++\n",
      "row number: 1 and case id: 20-CC-001003\n",
      "done\n",
      "20-CC-001003 was saved\n",
      "+++++++++++++++++++DONE+++++++++++++++++++++++++++++++++\n"
     ]
    }
   ],
   "source": [
    "#Return Most Recent Case for a given year\n",
    "searchpage = SearchPage(test_driver, 'https://hover.hillsclerk.com/html/case/caseSearch.html')\n",
    "#searchpage.most_recent_case(2020, 'CC')\n",
    "searchpage.final_scrape(ls, a, b)\n",
    "#01/01/2020"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['cool', 'bad']\n",
      "6\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "first print of list: ['01/01/2020']\n",
      "Already Loggged in\n",
      "delta is 14 days, 0:00:00 and last element in list is 01/01/2020\n",
      "FIRST ROUND: start: 01/01/2020 -- end: 01/15/2020\n",
      "+++++++++\n",
      "how many rows there are: 460\n",
      "+++++++++\n",
      "----------------------NEW WEEK SPAN----------------------------------\n",
      "Already Loggged in\n",
      "After first round: start: 01/16/2020 -- end: 01/29/2020\n",
      "+++++++++\n",
      "how many rows there are: 500\n",
      "+++++++++\n",
      "subtracting a day ---------\n",
      "----------------------NEW WEEK SPAN----------------------------------\n",
      "Already Loggged in\n",
      "After first round: start: 01/16/2020 -- end: 01/28/2020\n",
      "+++++++++\n",
      "how many rows there are: 500\n",
      "+++++++++\n",
      "subtracting a day ---------\n",
      "----------------------NEW WEEK SPAN----------------------------------\n",
      "Already Loggged in\n",
      "After first round: start: 01/16/2020 -- end: 01/27/2020\n",
      "+++++++++\n",
      "how many rows there are: 436\n",
      "+++++++++\n",
      "----------------------NEW WEEK SPAN----------------------------------\n",
      "Already Loggged in\n",
      "After first round: start: 01/28/2020 -- end: 02/10/2020\n",
      "+++++++++\n",
      "how many rows there are: 445\n",
      "+++++++++\n",
      "----------------------NEW WEEK SPAN----------------------------------\n",
      "Already Loggged in\n",
      "After first round: start: 02/11/2020 -- end: 02/24/2020\n",
      "+++++++++\n",
      "how many rows there are: 500\n",
      "+++++++++\n",
      "subtracting a day ---------\n",
      "----------------------NEW WEEK SPAN----------------------------------\n",
      "Already Loggged in\n",
      "After first round: start: 02/11/2020 -- end: 02/23/2020\n",
      "+++++++++\n",
      "how many rows there are: 499\n",
      "+++++++++\n",
      "----------------------NEW WEEK SPAN----------------------------------\n",
      "Already Loggged in\n",
      "After first round: start: 02/24/2020 -- end: 03/08/2020\n",
      "+++++++++\n",
      "how many rows there are: 395\n",
      "+++++++++\n",
      "----------------------NEW WEEK SPAN----------------------------------\n",
      "Already Loggged in\n",
      "After first round: start: 03/09/2020 -- end: 03/22/2020\n",
      "+++++++++\n",
      "how many rows there are: 371\n",
      "+++++++++\n",
      "----------------------NEW WEEK SPAN----------------------------------\n",
      "Already Loggged in\n",
      "After first round: start: 03/23/2020 -- end: 04/05/2020\n",
      "+++++++++\n",
      "how many rows there are: 183\n",
      "+++++++++\n",
      "----------------------NEW WEEK SPAN----------------------------------\n",
      "Already Loggged in\n",
      "After first round: start: 04/06/2020 -- end: 04/19/2020\n",
      "+++++++++\n",
      "how many rows there are: 76\n",
      "+++++++++\n",
      "----------------------NEW WEEK SPAN----------------------------------\n",
      "Already Loggged in\n",
      "After first round: start: 04/20/2020 -- end: 05/03/2020\n",
      "+++++++++\n",
      "how many rows there are: 102\n",
      "+++++++++\n",
      "----------------------NEW WEEK SPAN----------------------------------\n",
      "Already Loggged in\n",
      "After first round: start: 05/04/2020 -- end: 05/17/2020\n",
      "+++++++++\n",
      "how many rows there are: 114\n",
      "+++++++++\n",
      "----------------------NEW WEEK SPAN----------------------------------\n",
      "Already Loggged in\n",
      "After first round: start: 05/18/2020 -- end: 05/31/2020\n",
      "+++++++++\n",
      "how many rows there are: 107\n",
      "+++++++++\n",
      "----------------------NEW WEEK SPAN----------------------------------\n",
      "Already Loggged in\n",
      "After first round: start: 06/01/2020 -- end: 06/14/2020\n",
      "+++++++++\n",
      "how many rows there are: 124\n",
      "+++++++++\n",
      "----------------------NEW WEEK SPAN----------------------------------\n",
      "Already Loggged in\n",
      "After first round: start: 06/15/2020 -- end: 06/28/2020\n",
      "+++++++++\n",
      "how many rows there are: 139\n",
      "+++++++++\n",
      "----------------------NEW WEEK SPAN----------------------------------\n",
      "Already Loggged in\n",
      "After first round: start: 06/29/2020 -- end: 07/12/2020\n",
      "+++++++++\n",
      "how many rows there are: 66\n",
      "+++++++++\n",
      "----------------------NEW WEEK SPAN----------------------------------\n",
      "Already Loggged in\n",
      "After first round: start: 07/13/2020 -- end: 07/26/2020\n",
      "+++++++++\n",
      "how many rows there are: 80\n",
      "+++++++++\n",
      "----------------------NEW WEEK SPAN----------------------------------\n",
      "Already Loggged in\n",
      "After first round: start: 07/27/2020 -- end: 08/09/2020\n",
      "+++++++++\n",
      "how many rows there are: 130\n",
      "+++++++++\n",
      "----------------------NEW WEEK SPAN----------------------------------\n",
      "Already Loggged in\n",
      "After first round: start: 08/10/2020 -- end: 08/23/2020\n",
      "+++++++++\n",
      "how many rows there are: 342\n",
      "+++++++++\n",
      "----------------------NEW WEEK SPAN----------------------------------\n",
      "Already Loggged in\n",
      "After first round: start: 08/24/2020 -- end: 09/06/2020\n",
      "+++++++++\n",
      "how many rows there are: 293\n",
      "+++++++++\n",
      "----------------------NEW WEEK SPAN----------------------------------\n",
      "Already Loggged in\n",
      "After first round: start: 09/07/2020 -- end: 09/20/2020\n",
      "+++++++++\n",
      "how many rows there are: 348\n",
      "+++++++++\n",
      "----------------------NEW WEEK SPAN----------------------------------\n",
      "Already Loggged in\n",
      "After first round: start: 09/21/2020 -- end: 10/04/2020\n",
      "+++++++++\n",
      "how many rows there are: 426\n",
      "+++++++++\n",
      "----------------------NEW WEEK SPAN----------------------------------\n",
      "Already Loggged in\n",
      "After first round: start: 10/05/2020 -- end: 10/18/2020\n",
      "+++++++++\n",
      "how many rows there are: 484\n",
      "+++++++++\n",
      "----------------------NEW WEEK SPAN----------------------------------\n",
      "Already Loggged in\n",
      "After first round: start: 10/19/2020 -- end: 11/01/2020\n",
      "+++++++++\n",
      "how many rows there are: 429\n",
      "+++++++++\n",
      "----------------------NEW WEEK SPAN----------------------------------\n",
      "Already Loggged in\n",
      "After first round: start: 11/02/2020 -- end: 11/15/2020\n",
      "+++++++++\n",
      "how many rows there are: 423\n",
      "+++++++++\n",
      "----------------------NEW WEEK SPAN----------------------------------\n",
      "Already Loggged in\n",
      "After first round: start: 11/16/2020 -- end: 11/29/2020\n",
      "+++++++++\n",
      "how many rows there are: 500\n",
      "+++++++++\n",
      "subtracting a day ---------\n",
      "----------------------NEW WEEK SPAN----------------------------------\n",
      "Already Loggged in\n",
      "After first round: start: 11/16/2020 -- end: 11/28/2020\n",
      "+++++++++\n",
      "how many rows there are: 500\n",
      "+++++++++\n",
      "subtracting a day ---------\n",
      "----------------------NEW WEEK SPAN----------------------------------\n",
      "Already Loggged in\n",
      "After first round: start: 11/16/2020 -- end: 11/27/2020\n",
      "+++++++++\n",
      "how many rows there are: 498\n",
      "+++++++++\n",
      "----------------------NEW WEEK SPAN----------------------------------\n",
      "Already Loggged in\n",
      "After first round: start: 11/28/2020 -- end: 12/11/2020\n",
      "+++++++++\n",
      "how many rows there are: 429\n",
      "+++++++++\n",
      "----------------------NEW WEEK SPAN----------------------------------\n",
      "Already Loggged in\n",
      "After first round: start: 12/12/2020 -- end: 12/25/2020\n",
      "+++++++++\n",
      "how many rows there are: 418\n",
      "+++++++++\n",
      "----------------------NEW WEEK SPAN----------------------------------\n",
      "Already Loggged in\n",
      "After first round: start: 12/26/2020 -- end: 12/31/2020\n",
      "+++++++++\n",
      "how many rows there are: 148\n",
      "+++++++++\n",
      "----------------------NEW WEEK SPAN----------------------------------\n",
      "+++++++++++++++++++DONE+++++++++++++++++++++++++++++++++\n"
     ]
    }
   ],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Case Number: 20-CC-000216 \n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'20-CC-000216'"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
