{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from lxml import html\n",
    "from lxml import etree\n",
    "from fake_useragent import UserAgent\n",
    "from bs4 import BeautifulSoup\n",
    "import pandas as pd\n",
    "\n",
    "from io import StringIO, BytesIO\n",
    "import datetime\n",
    "from datetime import date\n",
    "from datetime import timedelta, datetime\n",
    "\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#from requests_base import RequestsPage\n",
    "\n",
    "\n",
    "#####Pages######\n",
    "##base\n",
    "class RequestsPage:\n",
    "        \n",
    "    def get_html(self, url, payload=None):\n",
    "        self.url = url\n",
    "        fakeuser = UserAgent()\n",
    "        headers = {'user-agent': fakeuser.chrome}\n",
    "        data = requests.get(url, headers=headers, params=payload)\n",
    "        #print(data.url)\n",
    "        return data\n",
    "\n",
    "    def save_html(self, data, filename):\n",
    "        self.file = open(filename, \"a\")\n",
    "        self.file.write(data)\n",
    "        self.file.close()\n",
    "        \n",
    "##config\n",
    "\n",
    "class ShelbyURLs:\n",
    "    #case_details = 'https://gscivildata.shelbycountytn.gov/pls/gnweb/ck_public_qry_doct.cp_dktrpt_docket_report?backto=C&case_id=2061459&begin_date=&end_date='\n",
    "    #case_details = 'https://gscivildata.shelbycountytn.gov/pls/gnweb/ck_public_qry_doct.cp_dktrpt_docket_report?backto=C&case_id={}&begin_date=&end_date='\n",
    "    case_details = 'https://gscivildata.shelbycountytn.gov/pls/gnweb/ck_public_qry_doct.cp_dktrpt_docket_report?'\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class NoDateDiscoveryMixIn():\n",
    "    \n",
    "    \n",
    "    def _get_today_date(self):\n",
    "        self.current_date = datetime.today().date()\n",
    "        \n",
    "    \n",
    "    def _clean_date(self, date):\n",
    "        self.date = date[0].split(\", \")\n",
    "        self.final_date = f'{self.date[2].strip()}-{self.date[1].split()[0]}-{self.date[1].split()[1].strip()[0:2]}'\n",
    "        self.clean_date = datetime.strptime(self.final_date, '%Y-%B-%d').date()\n",
    "        return(self.clean_date)\n",
    "\n",
    "  \n",
    "    def _create_tree(self):\n",
    "        self.parser = etree.HTMLParser()\n",
    "        self.tree = etree.parse(StringIO(self.output.text), self.parser)\n",
    "    \n",
    "    def _locators(self):\n",
    "        #self.case_present = self.tree.xpath('//*[contains(text(), \"No case was found\")]/text()')\n",
    "        #self.date = self._clean_date(self.tree.xpath('//table[2]//tr[2]//td[3]//text()'))\n",
    "        pass\n",
    "        \n",
    "        \n",
    "        \n",
    "  \n",
    "    def _search_no_case(self):\n",
    "        \n",
    "        self.case_present = self.tree.xpath(self.case_status)\n",
    "        ls_dates = []\n",
    "        counter = 0   \n",
    "        while len(self.case_present) == False:\n",
    "            counter = counter +1\n",
    "            date = self._clean_date(self.tree.xpath(self.filing_date))\n",
    "            \n",
    "            daily_average_filings = 40\n",
    "\n",
    "            if counter != 1:\n",
    "                latest_date = ls_dates.pop()\n",
    "                if ((date-latest_date).days)<0:\n",
    "                    date = latest_date\n",
    "                    \n",
    "            ls_dates.append(date)\n",
    "            days_between = (self.current_date - date).days\n",
    "\n",
    "            if days_between < 10:\n",
    "                daily_average_filings = 10\n",
    "            if days_between == 0:\n",
    "                days_between = 1\n",
    "\n",
    "            case_increment = days_between * daily_average_filings\n",
    "            self.case_number = self.case_number + case_increment\n",
    "            self.page_source(\"Shelby\", self.case_number)\n",
    "            self._create_tree()\n",
    "            self.case_present = self.tree.xpath(self.case_status)\n",
    "\n",
    "           \n",
    "        #pass\n",
    "\n",
    "    def _search_for_case(self):\n",
    "        \n",
    "        while len(self.case_present) == True:\n",
    "            self.case_number = self.case_number-1\n",
    "            self.page_source(\"Shelby\", self.case_number)\n",
    "            self._create_tree()\n",
    "            self.case_present = self.tree.xpath(self.case_status)\n",
    "            \n",
    "    def manuall_site_param(self):\n",
    "        raise DumbDeveloperException('This function requires a manual script. Are you a developer? Did you forget to overwrite manual_site_parm()')\n",
    "    \n",
    "        \n",
    "            \n",
    "                \n",
    "   \n",
    "    def most_recent_case(self, start_case, filing_date, case_status, driver=None):\n",
    "        \n",
    "        self.filing_date = filing_date\n",
    "        self.case_status = case_status\n",
    "        self.start_case = start_case\n",
    "        self._get_today_date()\n",
    "        self.page_source(\"Shelby\", self.start_case)\n",
    "        self._create_tree()\n",
    "        self._search_no_case()\n",
    "        self._search_for_case()\n",
    "        print(f'most recent case is: {self.case_number}')\n",
    "        return(self.case_number)\n",
    "       \n",
    "        #self.clean_date = self._clean_date()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "##search_page\n",
    "class SearchPage(RequestsPage, NoDateDiscoveryMixIn):\n",
    "    \n",
    "    \n",
    "    \n",
    "    def _build_payload(self):\n",
    "        self.payload = {\n",
    "            'backto' : \"C\",\n",
    "            'case_id':  self.case_number,\n",
    "            'begin_date': '',\n",
    "            'end_date' : ''\n",
    "                       }\n",
    "    \n",
    "    \n",
    "    def page_source(self, county, case_number):\n",
    "        self.county = county\n",
    "        \n",
    "        self.case_number = case_number\n",
    "        self._build_payload()\n",
    "        self.url = ShelbyURLs.case_details.format(self.case_number)\n",
    "        \n",
    "        self.output = self.get_html(self.url, payload = self.payload)\n",
    "        #print(self.url)\n",
    "        #print(\"+++\")\n",
    "        #print(self.output.url)\n",
    "        \n",
    "        #self.save_html(self.output, \"test2\")\n",
    "        \n",
    "    def most_recent_case(self, start_case):\n",
    "        super().most_recent_case(start_case ,'//table[2]//tr[2]//td[3]//text()','//*[contains(text(), \"No case was found\")]/text()' )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Parser():\n",
    "    def __init__(self):\n",
    "        self.lxml_parser = etree.HTMLParser()\n",
    "\n",
    "    \n",
    "    def open_html(self, html_file):\n",
    "        self.html_file = html_file\n",
    "        self.html = open(self.html_file, \"r\")\n",
    "        self.html = self.html.read()\n",
    "        return etree.parse(StringIO(self.html), self.lxml_parser)\n",
    "    \n",
    "    def _get_info(self, location):\n",
    "        self.location = location\n",
    "        return self.tree.xpath(self.location)\n",
    "    \n",
    "    def clean(self, dirty):\n",
    "        self.dirty = dirty\n",
    "        self.dirty = self.dirty.lower().strip().replace('\\n', '')\n",
    "        return self.dirty\n",
    "\n",
    "    def assign_element(self, location):\n",
    "        self.info = self._get_info(location)\n",
    "        if isinstance(self.info, list):\n",
    "            if len(self.info) == 0:\n",
    "                #print('length is 0')\n",
    "                return 'none'\n",
    "            elif self.info[0].text != None and self.clean(self.info[0].text) != '':\n",
    "                #print('position 1 is not none')\n",
    "                return self.clean(self.info[0].text)\n",
    "            else:\n",
    "                #print('should be returning string of none')\n",
    "                return 'none'\n",
    "        elif self.info == None:\n",
    "            #print('not a list, is none')\n",
    "            return 'none'\n",
    "        else:\n",
    "            #print('not a list, not none')\n",
    "            return self.info\n",
    "    \n",
    "    def assign_elements(self, location):\n",
    "        self.info = self._get_info(location)\n",
    "        return self.info\n",
    "        if isinstance(self.info, list):\n",
    "            if len(self.info) == 1:\n",
    "                raise ElementException('Element only returned one element. Try assign_element (singular)')\n",
    "            else:\n",
    "                return self.info\n",
    "        else:\n",
    "            raise ElementException('Element only returned one element. Try assign_element (singular).')\n",
    "    \n",
    "    #counts elements returned by assign_elements, returns number\n",
    "    def get_length(self, location):\n",
    "        self.info = self._get_info(location)\n",
    "        return len(self.info)\n",
    "    \n",
    "    # this function writes multiples 'none's to a given list until that list is 3 items long\n",
    "    def expand_list(self, list, length):\n",
    "        self.list = list\n",
    "        self.length = length\n",
    "        while len(self.list) < self.length:\n",
    "            try:\n",
    "                self.list.append('none')\n",
    "            except:\n",
    "                pass\n",
    "        return self.list\n",
    "\n",
    "    def more_than(self, list, count):\n",
    "        self.list = list\n",
    "        self.count = count\n",
    "        if len(self.list) > self.count:\n",
    "            return 'yes'\n",
    "        else:\n",
    "            return 'no'\n",
    "        \n",
    "    def text_between(self, text, before, after):\n",
    "        self.text = text\n",
    "        self.before = before\n",
    "        self.after = after\n",
    "        try:\n",
    "            self.parse = self.text.split(self.before)\n",
    "            self.parse = self.parse[1].split(self.after)\n",
    "            self.parse = self.clean(self.parse[0])\n",
    "        except:\n",
    "            self.parse = 'none'\n",
    "        return self.parse\n",
    "\n",
    "    def does_string_appear(self, text, string):\n",
    "        self.text = text\n",
    "        self.string = string\n",
    "        self.test = self.text.find(self.string)\n",
    "        if self.test != -1:\n",
    "            return 'yes'\n",
    "        else:\n",
    "            return 'no'\n",
    "    \n",
    "    #this function provides an entry_point to the best xpath logic for new users\n",
    "    #it follows this logic{div/table item is in}/{div/html element text is in}/{text to search}/{xpath to follow to get to relative field}\n",
    "    def string_search(self, text, table, route=None, text_location=None):\n",
    "        self.text = text\n",
    "        self.table = table\n",
    "        self.route = route\n",
    "        self.text_location = text_location\n",
    "        if self.text_location == None and self.route == None:\n",
    "            #('no location and no route')\n",
    "            return self.assign_element(f'{self.table}//*[contains(text(), \"{text}\")]')\n",
    "        elif self.text_location == None and self.route != None:\n",
    "            #('no location')\n",
    "            return self.assign_element(f'{self.table}//*[contains(text(), \"{text}\")]/{self.route}')\n",
    "        elif self.text_location != None and self.route == None:\n",
    "            #('no route')\n",
    "            return self.assign_element(f'{self.table}//{self.text_location}[contains(text(), \"{text}\")]')\n",
    "        elif self.text_location != None and self.route != None:\n",
    "            #('location and route')\n",
    "            return self.assign_element(f'{self.table}//{self.text_location}[contains(text(), \"{text}\")]/{self.route}')\n",
    "    \n",
    "    \n",
    "    # this function creates a new database and failure log but wont overwrite existing one\n",
    "    def create_dataframe(self, database_name, header):\n",
    "        self.database_name = database_name\n",
    "        self.header = header\n",
    "        self.file = f'{file_path}/{self.database_name}'\n",
    "        if path.exists(self.file):\n",
    "            print('CSV already exists.')\n",
    "        else:\n",
    "            with open(self.file, 'w', newline='') as self.outfile:\n",
    "                self.writer = csv.writer(self.outfile)\n",
    "                self.writer.writerow(self.header)\n",
    "            print('New CSV created.')\n",
    "    \n",
    "    def write_data(self, data_out, database_name):\n",
    "        #writing data to csv\n",
    "        self.data_out = data_out\n",
    "        self.database_name = database_name\n",
    "        self.file = f'{file_path}/{self.database_name}'\n",
    "        with open(self.file, 'a', newline='') as self.outfile:\n",
    "            self.writer = csv.writer(self.outfile, delimiter=',')\n",
    "            self.writer.writerow(self.data_out)\n",
    "            \n",
    "    def write_json_data(self, data_out, database_name):\n",
    "        #writing data to json\n",
    "        self.data_out = data_out\n",
    "        self.database_name = database_name\n",
    "        self.file = f'{file_path}/{self.database_name}'\n",
    "        with open(self.file, 'w') as self.outfile:\n",
    "            json.dump(self.data_out, self.outfile)\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ShelbyParser(Parser):\n",
    "    \n",
    "    \n",
    "        \n",
    "    def shelby_eviction(self, tree):\n",
    "        self.tree = tree\n",
    "        \n",
    "        #Initialize storage containers\n",
    "        self.case_object = dict()\n",
    "        self.party_obj = []\n",
    "        self.docket_obj = []\n",
    "        \n",
    "        ##table locations\n",
    "        self.case_description_table = '//*[contains(text(), \"Case Description\")]/parent::node()/parent::node()//following-sibling::table[1]'\n",
    "        self.report_selection_criteria_table = '//*[contains(text(), \"Report Selection Criteria\")]/parent::node()/parent::node()//following-sibling::table[1]' \n",
    "        self.case_parties_table = '//*[contains(text(), \"Case Parties\")]/parent::node()//following-sibling::table[1]'\n",
    "        self.docket_entries_table = '//*[contains(text(), \"Docket Entries\")]/parent::node()/parent::node()//following-sibling::table[1]'\n",
    "        self.get_horizontal_info = '/parent::node()//following-sibling::td[1]'\n",
    "        self.rows_route = 'descendant::tr'\n",
    "        \n",
    "        ##Horizontal information\n",
    "        self.case_id = self.string_search(\"Case ID\", self.report_selection_criteria_table, route = self.get_horizontal_info, text_location = 'b')\n",
    "        self.filing_date = self.string_search(\"Filing Date\", self.case_description_table, route = self.get_horizontal_info, text_location = 'b')\n",
    "        self.type = self.string_search(\"Type\", self.case_description_table, route = self.get_horizontal_info, text_location = 'b')\n",
    "        self.status = self.string_search(\"Status\", self.case_description_table, route = self.get_horizontal_info, text_location = 'b')\n",
    "        \n",
    "        ##Vertical Information\n",
    "        \n",
    "        \n",
    "        ####Case Parties\n",
    "        self.case_parties_row_locator = f'{self.case_parties_table}/{self.rows_route}'        \n",
    "        self.rows = self.get_length(f'{self.case_parties_row_locator}')\n",
    "                \n",
    "        self.info_rows_index = list(range(1,self.rows))\n",
    "        self.info_row_index_grouped = list(zip(*[iter(self.info_rows_index)]*3))\n",
    "        \n",
    "        \n",
    "        for index in self.info_row_index_grouped:\n",
    "            self.index = index  \n",
    "            #plus 1 to account for first row being headers\n",
    "            self.first_row = index[0]+1\n",
    "            self.second_row = index[1]+1\n",
    "            \n",
    "    \n",
    "            self.xpath1 = f'{self.case_parties_row_locator}[{self.first_row}]/td'\n",
    "            self.xpath2 =  f'{self.case_parties_row_locator}[{self.second_row}]/td'\n",
    "\n",
    "\n",
    "            self.seq = self.assign_element(f'{self.xpath1}[1]')\n",
    "            self.assoc = self.assign_element(f'{self.xpath1}[2]')\n",
    "            self.expn_date = self.assign_element(f'{self.xpath1}[3]')\n",
    "            self.type = self.assign_element(f'{self.xpath1}[4]')\n",
    "            self.id = self.assign_element(f'{self.xpath1}[5]')\n",
    "            self.name = self.assign_element(f'{self.xpath1}[6]')\n",
    "            \n",
    "            self.address = self.assign_element(f'{self.xpath2}[2]')\n",
    "            self.aliases = self.assign_element(f'{self.xpath2}[4]')\n",
    "            \n",
    "            self.party_dict = {\"seq\":self.seq , \"assoc\":self.assoc,\"expnDate\":self.expn_date,\"type\":self.type,\"id\":self.id ,\"name\":self.name, \"address\":self.address,\"aliases\" :self.aliases } \n",
    "            self.party_obj.append(self.party_dict)\n",
    "\n",
    "        \n",
    "\n",
    "        ####Docket Entries\n",
    "        self.docket_entries_row_locator = f'{self.docket_entries_table}/{self.rows_route}'        \n",
    "        self.rows = self.get_length(f'{self.docket_entries_row_locator}')\n",
    "                \n",
    "        self.info_rows_index = list(range(1,self.rows))\n",
    "        self.info_row_index_grouped = list(zip(*[iter(self.info_rows_index)]*3))\n",
    "        \n",
    "        \n",
    "        for index in self.info_row_index_grouped:\n",
    "            self.index = index  \n",
    "            #plus 1 to account for first row being headers\n",
    "            self.first_row = index[0]+1\n",
    "            self.second_row = index[1]+1\n",
    "            \n",
    "    \n",
    "            self.xpath1 = f'{self.docket_entries_row_locator}[{self.first_row}]/td'\n",
    "            self.xpath2 =  f'{self.docket_entries_row_locator}[{self.second_row}]/td'\n",
    "\n",
    "\n",
    "            self.filingDate = self.assign_element(f'{self.xpath1}[1]')\n",
    "            self.description = self.assign_element(f'{self.xpath1}[2]')\n",
    "            self.name = self.assign_element(f'{self.xpath1}[3]')\n",
    "            self.monetary = self.assign_element(f'{self.xpath1}[4]')\n",
    "            \n",
    "            \n",
    "            self.entry = self.assign_element(f'{self.xpath2}[2]')\n",
    "            \n",
    "            \n",
    "            self.docket_dict = {\"filingDate\": self.filingDate,  \"description\":self.description, \"name\": self.name, \"monetary\": self.monetary, \"entry\":self.entry}\n",
    "\n",
    "            self.docket_obj.append(self.docket_dict)\n",
    "            \n",
    "        #Compile final data\n",
    "        self.case_object[\"case_id\"] = self.case_id        \n",
    "        self.case_object[\"filing_date\"] = self.filing_date\n",
    "        self.case_object[\"type\"] = self.type\n",
    "        self.case_object[\"status\"] = self.status\n",
    "        self.case_object[\"case_parties\"] = self.party_obj\n",
    "        self.case_object[\"docket_entries\"] = self.docket_obj\n",
    "        \n",
    "        print(self.case_object)\n",
    "        return(self.case_object)\n",
    "        \n",
    "\n",
    "\n",
    "        \n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#file_path = \"C:/Users/nicho/Documents\"\n",
    "\n",
    "#class Shelby():\n",
    " #   def parse_cases(self):\n",
    "  #      parse = ShelbyParser()\n",
    "   #     self.file = \"C:/Users/nicho/Documents/Code/howard-center-webscrapers2/testing/1724299_20201017-004342\"\n",
    "    #    #self.file = \"C:/Users/nicho/Documents/Code/howard-center-webscrapers2/testing/1734725_20201017-005619\"\n",
    "     #   #self.file = \"C:/Users/nicho/Documents/Code/howard-center-webscrapers2/testing/2035896_20201019-113043\"\n",
    "        \n",
    "      #  self.tree = parse.open_html(self.file)\n",
    "       # self.data_out = parse.shelby_eviction(self.tree)\n",
    "        #parse.write_json_data(self.data_out, \"test_oops6.json\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#test = Shelby()\n",
    "#test.parse_cases()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "most recent case is: 2080041\n"
     ]
    }
   ],
   "source": [
    "test = SearchPage()\n",
    "test.most_recent_case(2061459)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "43449\n"
     ]
    }
   ],
   "source": [
    "#1870952\n",
    "last_case = 2074248\n",
    "ls = []\n",
    "for case_number in range(2030800,last_case+1):\n",
    "\n",
    "    url = f'https://gscivildata.shelbycountytn.gov/pls/gnweb/ck_public_qry_doct.cp_dktrpt_docket_report?backto=C&case_id={case_number}&begin_date=&end_date='\n",
    "    ls.append(url)\n",
    "    \n",
    "print(len(ls))\n",
    "\n",
    "scraper = 1\n",
    "\n",
    "if scraper == 1:\n",
    "    a = 0 + 2030800\n",
    "    b=4300 +2030800\n",
    "if scraper == 2:\n",
    "    a = 4301 + 2030800\n",
    "    b=8601 + 2030800\n",
    "if scraper == 3:\n",
    "    a = 8602 + 2030800\n",
    "    b=12902 + 2030800\n",
    "if scraper == 4:\n",
    "    a = 12903 + 2030800\n",
    "    b=17203 + 2030800\n",
    "if scraper == 5:\n",
    "    a = 17204 + 2030800\n",
    "    b=21504 + 2030800\n",
    "if scraper == 6:\n",
    "    a = 21505 + 2030800\n",
    "    b=25805 + 2030800\n",
    "if scraper == 7:\n",
    "    a = 25806 + 2030800\n",
    "    b=30106 + 2030800\n",
    "if scraper == 8:\n",
    "    a = 30107 + 2030800\n",
    "    b=34407 + 2030800\n",
    "if scraper == 9:\n",
    "    a = 34408 + 2030800\n",
    "    b=38708 + 2030800\n",
    "if scraper == 10:\n",
    "    a = 38709 + 2030800\n",
    "    b=2074248\n",
    "\n",
    "#if scraper = \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def download_url(url):\n",
    "    \n",
    "    #timestr = time.strftime(\"%Y%m%d-%H%M%S\")\n",
    "    fakeuser = UserAgent()\n",
    "    headers = {'user-agent': fakeuser.chrome}\n",
    "    resp = requests.get(url,headers=headers)\n",
    "    title = ''.join(x for x in url if x.isnumeric()) \n",
    "    print(title)\n",
    "    with open(f'C:/Users/nicho/Documents/Code/howard-center-webscrapers2/Shelby/All 2020/{str(scraper)}/{title}', \"wb\") as fh:\n",
    "        fh.write(resp.content)\n",
    "        \n",
    "\n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2030800\n",
      "2030801\n",
      "2030802\n",
      "2030803\n",
      "2030804\n",
      "2030805\n",
      "2030806\n",
      "2030807\n",
      "2030808\n",
      "2030809\n",
      "2030810\n",
      "2030811\n",
      "2030812\n",
      "2030813\n",
      "2030814\n",
      "2030815\n",
      "2030816\n",
      "2030817\n",
      "2030818\n",
      "2030819\n",
      "2030820\n",
      "2030821\n",
      "2030822\n",
      "2030823\n",
      "2030824\n",
      "2030825\n",
      "2030826\n",
      "2030827\n",
      "2030828\n",
      "2030829\n",
      "2030830\n",
      "2030831\n",
      "2030832\n",
      "2030833\n",
      "2030834\n",
      "2030835\n",
      "2030836\n",
      "2030837\n",
      "2030838\n",
      "2030839\n",
      "2030840\n",
      "2030841\n",
      "2030842\n",
      "2030843\n",
      "2030844\n",
      "2030845\n",
      "2030846\n",
      "2030847\n",
      "2030848\n",
      "2030849\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-15-1b64769aafe7>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mcase\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mls\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0ma\u001b[0m\u001b[1;33m:\u001b[0m\u001b[0mb\u001b[0m\u001b[1;33m+\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m     \u001b[0mdownload_url\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcase\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m<ipython-input-13-7db5650fe32f>\u001b[0m in \u001b[0;36mdownload_url\u001b[1;34m(url)\u001b[0m\n\u001b[0;32m      4\u001b[0m     \u001b[0mfakeuser\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mUserAgent\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m     \u001b[0mheaders\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m{\u001b[0m\u001b[1;34m'user-agent'\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mfakeuser\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mchrome\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 6\u001b[1;33m     \u001b[0mresp\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mrequests\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0murl\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mheaders\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mheaders\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      7\u001b[0m     \u001b[0mtitle\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m''\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[1;32min\u001b[0m \u001b[0murl\u001b[0m \u001b[1;32mif\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0misnumeric\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      8\u001b[0m     \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtitle\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\nicho\\.virtualenvs\\howard-center-webscrapers2-4llosrqu\\lib\\site-packages\\requests\\api.py\u001b[0m in \u001b[0;36mget\u001b[1;34m(url, params, **kwargs)\u001b[0m\n\u001b[0;32m     74\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     75\u001b[0m     \u001b[0mkwargs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msetdefault\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'allow_redirects'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 76\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0mrequest\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'get'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0murl\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mparams\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mparams\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     77\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     78\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\nicho\\.virtualenvs\\howard-center-webscrapers2-4llosrqu\\lib\\site-packages\\requests\\api.py\u001b[0m in \u001b[0;36mrequest\u001b[1;34m(method, url, **kwargs)\u001b[0m\n\u001b[0;32m     59\u001b[0m     \u001b[1;31m# cases, and look like a memory leak in others.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     60\u001b[0m     \u001b[1;32mwith\u001b[0m \u001b[0msessions\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mSession\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0msession\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 61\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0msession\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrequest\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmethod\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mmethod\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0murl\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0murl\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     62\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     63\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\nicho\\.virtualenvs\\howard-center-webscrapers2-4llosrqu\\lib\\site-packages\\requests\\sessions.py\u001b[0m in \u001b[0;36mrequest\u001b[1;34m(self, method, url, params, data, headers, cookies, files, auth, timeout, allow_redirects, proxies, hooks, stream, verify, cert, json)\u001b[0m\n\u001b[0;32m    528\u001b[0m         }\n\u001b[0;32m    529\u001b[0m         \u001b[0msend_kwargs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msettings\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 530\u001b[1;33m         \u001b[0mresp\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mprep\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0msend_kwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    531\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    532\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mresp\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\nicho\\.virtualenvs\\howard-center-webscrapers2-4llosrqu\\lib\\site-packages\\requests\\sessions.py\u001b[0m in \u001b[0;36msend\u001b[1;34m(self, request, **kwargs)\u001b[0m\n\u001b[0;32m    641\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    642\u001b[0m         \u001b[1;31m# Send the request\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 643\u001b[1;33m         \u001b[0mr\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0madapter\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrequest\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    644\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    645\u001b[0m         \u001b[1;31m# Total elapsed time of the request (approximately)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\nicho\\.virtualenvs\\howard-center-webscrapers2-4llosrqu\\lib\\site-packages\\requests\\adapters.py\u001b[0m in \u001b[0;36msend\u001b[1;34m(self, request, stream, timeout, verify, cert, proxies)\u001b[0m\n\u001b[0;32m    437\u001b[0m         \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    438\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mchunked\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 439\u001b[1;33m                 resp = conn.urlopen(\n\u001b[0m\u001b[0;32m    440\u001b[0m                     \u001b[0mmethod\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mrequest\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmethod\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    441\u001b[0m                     \u001b[0murl\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0murl\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\nicho\\.virtualenvs\\howard-center-webscrapers2-4llosrqu\\lib\\site-packages\\urllib3\\connectionpool.py\u001b[0m in \u001b[0;36murlopen\u001b[1;34m(self, method, url, body, headers, retries, redirect, assert_same_host, timeout, pool_timeout, release_conn, chunked, body_pos, **response_kw)\u001b[0m\n\u001b[0;32m    668\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    669\u001b[0m             \u001b[1;31m# Make the request on the httplib connection object.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 670\u001b[1;33m             httplib_response = self._make_request(\n\u001b[0m\u001b[0;32m    671\u001b[0m                 \u001b[0mconn\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    672\u001b[0m                 \u001b[0mmethod\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\nicho\\.virtualenvs\\howard-center-webscrapers2-4llosrqu\\lib\\site-packages\\urllib3\\connectionpool.py\u001b[0m in \u001b[0;36m_make_request\u001b[1;34m(self, conn, method, url, timeout, chunked, **httplib_request_kw)\u001b[0m\n\u001b[0;32m    424\u001b[0m                     \u001b[1;31m# Python 3 (including for exceptions like SystemExit).\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    425\u001b[0m                     \u001b[1;31m# Otherwise it looks like a bug in the code.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 426\u001b[1;33m                     \u001b[0msix\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mraise_from\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    427\u001b[0m         \u001b[1;32mexcept\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mSocketTimeout\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mBaseSSLError\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mSocketError\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    428\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_raise_timeout\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0merr\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0murl\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0murl\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtimeout_value\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mread_timeout\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\nicho\\.virtualenvs\\howard-center-webscrapers2-4llosrqu\\lib\\site-packages\\urllib3\\packages\\six.py\u001b[0m in \u001b[0;36mraise_from\u001b[1;34m(value, from_value)\u001b[0m\n",
      "\u001b[1;32mc:\\users\\nicho\\.virtualenvs\\howard-center-webscrapers2-4llosrqu\\lib\\site-packages\\urllib3\\connectionpool.py\u001b[0m in \u001b[0;36m_make_request\u001b[1;34m(self, conn, method, url, timeout, chunked, **httplib_request_kw)\u001b[0m\n\u001b[0;32m    419\u001b[0m                 \u001b[1;31m# Python 3\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    420\u001b[0m                 \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 421\u001b[1;33m                     \u001b[0mhttplib_response\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mconn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mgetresponse\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    422\u001b[0m                 \u001b[1;32mexcept\u001b[0m \u001b[0mBaseException\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    423\u001b[0m                     \u001b[1;31m# Remove the TypeError from the exception chain in\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\python38\\lib\\http\\client.py\u001b[0m in \u001b[0;36mgetresponse\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   1345\u001b[0m         \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1346\u001b[0m             \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1347\u001b[1;33m                 \u001b[0mresponse\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbegin\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1348\u001b[0m             \u001b[1;32mexcept\u001b[0m \u001b[0mConnectionError\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1349\u001b[0m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mclose\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\python38\\lib\\http\\client.py\u001b[0m in \u001b[0;36mbegin\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    305\u001b[0m         \u001b[1;31m# read until we get a non-100 response\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    306\u001b[0m         \u001b[1;32mwhile\u001b[0m \u001b[1;32mTrue\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 307\u001b[1;33m             \u001b[0mversion\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mstatus\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mreason\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_read_status\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    308\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mstatus\u001b[0m \u001b[1;33m!=\u001b[0m \u001b[0mCONTINUE\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    309\u001b[0m                 \u001b[1;32mbreak\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\python38\\lib\\http\\client.py\u001b[0m in \u001b[0;36m_read_status\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    266\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    267\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_read_status\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 268\u001b[1;33m         \u001b[0mline\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mstr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreadline\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0m_MAXLINE\u001b[0m \u001b[1;33m+\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"iso-8859-1\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    269\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mline\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m>\u001b[0m \u001b[0m_MAXLINE\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    270\u001b[0m             \u001b[1;32mraise\u001b[0m \u001b[0mLineTooLong\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"status line\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\python38\\lib\\socket.py\u001b[0m in \u001b[0;36mreadinto\u001b[1;34m(self, b)\u001b[0m\n\u001b[0;32m    667\u001b[0m         \u001b[1;32mwhile\u001b[0m \u001b[1;32mTrue\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    668\u001b[0m             \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 669\u001b[1;33m                 \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_sock\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrecv_into\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mb\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    670\u001b[0m             \u001b[1;32mexcept\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    671\u001b[0m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_timeout_occurred\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mTrue\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\python38\\lib\\ssl.py\u001b[0m in \u001b[0;36mrecv_into\u001b[1;34m(self, buffer, nbytes, flags)\u001b[0m\n\u001b[0;32m   1239\u001b[0m                   \u001b[1;34m\"non-zero flags not allowed in calls to recv_into() on %s\"\u001b[0m \u001b[1;33m%\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1240\u001b[0m                   self.__class__)\n\u001b[1;32m-> 1241\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mread\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnbytes\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbuffer\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1242\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1243\u001b[0m             \u001b[1;32mreturn\u001b[0m \u001b[0msuper\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrecv_into\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbuffer\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnbytes\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mflags\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\python38\\lib\\ssl.py\u001b[0m in \u001b[0;36mread\u001b[1;34m(self, len, buffer)\u001b[0m\n\u001b[0;32m   1097\u001b[0m         \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1098\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mbuffer\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1099\u001b[1;33m                 \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_sslobj\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mread\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbuffer\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1100\u001b[0m             \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1101\u001b[0m                 \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_sslobj\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mread\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
